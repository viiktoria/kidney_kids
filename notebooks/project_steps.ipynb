{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a08191c",
   "metadata": {},
   "source": [
    "This Notebook is meant to provide all the steps needed in achieveing our goals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd82f5f",
   "metadata": {},
   "source": [
    "## Download the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('path to the file') # Super straightforward to read a csv from a link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e2526",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5196ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dataset = pd.concat([features_concatenated, label_encoded_target], axis = 1)\n",
    "# checking wether there is any bug in the datasets\n",
    "# data['feature'].value_counts() # value_counts rank by descending order (the different unique values of a Pandas Series)\n",
    "# convert the numbers to proper numbers if needed\n",
    "# data['feature'] = data['feature'].map(the appropriate function)\n",
    "# Double-check that this mapping went well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd18f96",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a547a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop_duplicates().reset_index(drop = True)                 # no need to remember the previous index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba42dfc9",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2588241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the NaN (data.isnull().sum())\n",
    "# impute data if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3d662",
   "metadata": {},
   "source": [
    "## Features and target (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ae257",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e935d23",
   "metadata": {},
   "source": [
    "### visualize numercial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c98e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.select_dtypes(exclude = ['object'])  # selecting only the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f6a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each feature, display \n",
    "# the histogram to approximate the density\n",
    "# the boxplot to spot outliers\n",
    "# the qqplot to have a better sense of the \"gaussianity\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959d006",
   "metadata": {},
   "source": [
    "### create a copy of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97e74466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_scaled = cars_num.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705f156",
   "metadata": {},
   "source": [
    "#### Without the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a67d86",
   "metadata": {},
   "source": [
    "###### numerical features : scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "077c1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_standard = [appropriate features]\n",
    "#features_robust = [appropriate features]\n",
    "#features_minmax = [appropriate features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4bdccc",
   "metadata": {},
   "source": [
    "##### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a8d2275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_categorical = X.select_dtypes(include = ['object']) # focusing on the categorical variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b5094b",
   "metadata": {},
   "source": [
    "##### check whether we need to use drop if_binary or not  for each categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e92552c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for categorical_feature in cars_categorical.columns:\n",
    " #   print(\"-\"*50)\n",
    "  #  print(f\"Number of unique occurences for the categorical feature {categorical_feature}\")\n",
    "   # display(cars_categorical[categorical_feature].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa80d4",
   "metadata": {},
   "source": [
    "##### one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e096efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe = OneHotEncoder(sparse = False) # sparse matrix, sparse cheese, ....\n",
    "# ohe.fit(data_categorical[[\"feature\"]])\n",
    "# ohe.categories_ # such an ugly list\n",
    "# ohe.categories_[0] # numpy arrayt of the detected categories of the enginetype feature\n",
    "# list(ohe.categories_[0]) # better as a list we could iterate over\n",
    "# renamed_enginetype_columns = [\"enginetype_\"+blabla for blabla in list(ohe.categories_[0])]\n",
    "# enginetype_encoded = pd.DataFrame(enginetype_encoded, columns = renamed_enginetype_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8a1c8",
   "metadata": {},
   "source": [
    "##### Concatenate all preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25fed8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating them all, axis 1 \n",
    "# stands for \"columns\" stacked side-by-side together\n",
    "\n",
    "#features_concatenated = pd.concat([data_scaled, data_encoded, aspiration_encoded], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cdedcf",
   "metadata": {},
   "source": [
    "##### label-encode the categorigal target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bd36c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_encoder = LabelEncoder()\n",
    "\n",
    "#label_encoded_target = pd.DataFrame(label_encoder.fit_transform(y), columns = [\"target\"])\n",
    "#label_encoded_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557de860",
   "metadata": {},
   "source": [
    "##### final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce35df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_dataset = pd.concat([features_concatenated, label_encoded_target], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f0963c",
   "metadata": {},
   "source": [
    "#### With pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46736e69",
   "metadata": {},
   "source": [
    "##### chain the steps in a sequence : eg: impute, then scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5de0c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = Pipeline([\n",
    " #   ('imputer', SimpleImputer()),\n",
    "  #  ('scaler', StandardScaler())\n",
    "#])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d285bc",
   "metadata": {},
   "source": [
    "##### apply specific changes to specific columns in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1dbc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute then Scale for numerical variables: \n",
    "# num_transformer = Pipeline([\n",
    "  #  ('imputer', SimpleImputer()),\n",
    "   # ('scaler', StandardScaler())])\n",
    "\n",
    "## Encode categorical variables\n",
    "#cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Paralellize \"num_transformer\" and \"One hot encoder\"\n",
    "#preprocessor = ColumnTransformer([\n",
    " #   ('num_tr', num_transformer, [corresponding features]),\n",
    "  #  ('cat_tr', cat_transformer, [corresponding features])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf9aab2",
   "metadata": {},
   "source": [
    "##### to visualize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94137abe",
   "metadata": {},
   "outputs": [],
   "source": [
    " # visualizing pipelines in HTML\n",
    "#from sklearn import set_config; set_config(display='diagram')\n",
    "#preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea388f41",
   "metadata": {},
   "source": [
    "##### transformed data (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b0806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "#display(X_train.head(3))\n",
    "#display(pd.DataFrame(X_train_transformed).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f79544",
   "metadata": {},
   "source": [
    "##### get the feature names back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c3b42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should be fixed in Scikit-Learn 1.0.2: all transformers will have this method.\n",
    "## SimpleImputer does not have a get_feature_names_out, so we need to add it manually.\n",
    "#SimpleImputer.get_feature_names_out = (lambda self, names=None: self.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5f61876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your feature\n",
    "#preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6273d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(X_train_transformed, \n",
    " #            columns=preprocessor.get_feature_names_out()\n",
    "  #          ).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef3d51",
   "metadata": {},
   "source": [
    "##### do you want to left some features untouched?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff223ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = ColumnTransformer([\n",
    "  #  ('num_tr', num_transformer, ['age','bmi']),\n",
    "   # ('cat_tr', cat_transformer, ['region','smoker'])],\n",
    "    #remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b2a4b",
   "metadata": {},
   "source": [
    "##### we can as well include functiontransformer in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a transformer that compresses data to 2 digits (for instance!)\n",
    "# rounder = FunctionTransformer(np.round)\n",
    "# rounder = FunctionTransformer(lambda array: np.round(array, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f79229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
